{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elegant-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loose-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the files names at the folder\n",
    "def nameOfFiles():\n",
    "    result = [f for f in listdir(\"files\") if isfile(join(\"files\", f))]\n",
    "    return(result)\n",
    "nameOfFiles()\n",
    "\n",
    "#calculate the digest of each file and append to a final file\n",
    "#that will later save to a txt\n",
    "def main():\n",
    "    filesHash = ''\n",
    "    sha512 = hashlib.sha512()\n",
    "    checkFileNames = nameOfFiles()\n",
    "    for i in checkFileNames:\n",
    "        with open(\"files/\"+ i, \"rb\") as f:\n",
    "            while True:\n",
    "                data = f.read()\n",
    "                if not data:\n",
    "                    break\n",
    "                sha512.update(data)\n",
    "                filesHash+=(sha512.hexdigest())\n",
    "    return(filesHash)\n",
    "\n",
    "def createControlFile():\n",
    "    with open('fileControlData.txt','w',encoding = 'utf-8') as f:\n",
    "        for i in fileControl: f.write(i)\n",
    "    print(\"File generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjustable-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesNames = nameOfFiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "appropriate-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filesNames ['normalizer.exe']\n",
      "A file was added, do you wanna to recreate the control File?(y/n)y\n",
      "File generated!\n",
      "['normalizer.exe'] normalizer.exe\n",
      "['normalizer.exe'] normalizer3.exe\n",
      "1234\n",
      "\u001b[32m[*] Features extracted successfully.\n",
      "\u001b[0m\n",
      "already saved to the database\n"
     ]
    }
   ],
   "source": [
    "fileControl = main()\n",
    "\n",
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "# while True:\n",
    "print(\"filesNames\", filesNames)\n",
    "if os.path.exists(\"fileControlData.txt\") is True:\n",
    "    with open('fileControlData.txt','r',encoding = 'utf-8') as file:\n",
    "        file = file.read()\n",
    "        if file == fileControl:\n",
    "            print(\"The files are intact!\")\n",
    "        else:\n",
    "            if len(fileControl)> len(file):\n",
    "                answer = input(\"A file was added, do you wanna to recreate the control File?(y/n)\").lower()\n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "                for curFile in os.listdir(\"files\"):\n",
    "                    ff = curFile\n",
    "    #                     break\n",
    "                    print(filesNames, ff)\n",
    "                    if ff not in filesNames: \n",
    "                        print(1234)\n",
    "                        features = extract_features('files/' + ff) \n",
    "                        data2 =  {\n",
    "                                   \"Machine\" : [],\n",
    "                                    \"DebugSize\" :[],\n",
    "                                    \"DebugRVA\" :  [],\n",
    "                                    \"MajorImageVersion\" : [],\n",
    "                                    \"MajorOSVersion\" : [],\n",
    "                                    \"ExportRVA\" : [],\n",
    "                                    \"ExportSize\": [],\n",
    "                                    \"IatVRA\" : [],\n",
    "                                    \"MajorLinkerVersion\" : [],\n",
    "                                    \"MinorLinkerVersion\" : [],\n",
    "                                    \"NumberOfSections\" : [],\n",
    "                                    \"SizeOfStackReserve\" : [],\n",
    "                                    \"DllCharacteristics\" :  [],\n",
    "                                    \"ResourceSize\" : [],\n",
    "                                    \"BitcoinAddresses\" : []\n",
    "                                }\n",
    "                        print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "                        data2[\"Machine\"].append(features[2])\n",
    "                        data2[\"DebugSize\"].append(features[3])\n",
    "                        data2[\"DebugRVA\"].append(features[4])\n",
    "                        data2[\"MajorImageVersion\"].append(features[5])\n",
    "                        data2[\"MajorOSVersion\"].append(features[6])\n",
    "                        data2[\"ExportRVA\"].append(features[7])\n",
    "                        data2[\"ExportSize\"].append(features[8])\n",
    "                        data2[\"IatVRA\"].append(features[9])\n",
    "                        data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "                        data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "                        data2[\"NumberOfSections\"].append(features[12])\n",
    "                        data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "                        data2[\"DllCharacteristics\"].append(features[14])\n",
    "                        data2[\"ResourceSize\"].append(features[15])\n",
    "                        data2[\"BitcoinAddresses\"].append(features[16])\n",
    "                        url = \"http://127.0.0.1:8000/predict/\"\n",
    "                        res = requests.post(url, data2)\n",
    "                        res = res.json()\n",
    "                        prediction = res['prediction']\n",
    "                        prediction[0]\n",
    "                    #     print(\"This is the prediction for the file\", res.text)\n",
    "                        info1 = {\n",
    "                        'filename':features[0],\n",
    "                        'prediction':prediction[0],\n",
    "                        'date':datetime.datetime.utcnow()\n",
    "                        }\n",
    "                        collection.insert_one(info1)\n",
    "                        print(\"already saved to the database\")\n",
    "            elif len(fileControl)< len(file): \n",
    "                answer = input(\"A file was removed, do you wanna to recreate the control File?(y/n)\").lower()\n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "            else:\n",
    "                answer = input(\"The files have been changed, do you wanna to recreate the control File?(y/n)\").lower()            \n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "                    \n",
    "            filesNames = nameOfFiles()#update file names\n",
    "else:\n",
    "    createControlFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-bleeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compliant-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bson.objectid import ObjectId\n",
    "from pandas.io.json import json_normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protecting-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://127.0.0.1:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dominican-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a database\n",
    "mydatabase = client['Security']\n",
    "\n",
    "# Creating a collection in the ['Students'] database; Students_scores\n",
    "collection = mydatabase['base_tutorial']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "common-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1829a62d040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting records into the database; for one record\n",
    "info1 = {\n",
    "    'filename':'file.exe',\n",
    "    'prediction':1,\n",
    "    'date':datetime.datetime.utcnow()\n",
    "}\n",
    "collection.insert_one(info1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-sight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ignored-front",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Collection' object is not callable. If you meant to call the 'getIndexes' method on a 'Collection' object it is failing because no such method exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-873d68ce13ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmydatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetIndexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3483\u001b[0m                             \u001b[1;34m\"exists.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m                             self.__name)\n\u001b[1;32m-> 3485\u001b[1;33m         raise TypeError(\"'Collection' object is not callable. If you meant to \"\n\u001b[0m\u001b[0;32m   3486\u001b[0m                         \u001b[1;34m\"call the '%s' method on a 'Collection' object it is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3487\u001b[0m                         \u001b[1;34m\"failing because no such method exists.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Collection' object is not callable. If you meant to call the 'getIndexes' method on a 'Collection' object it is failing because no such method exists."
     ]
    }
   ],
   "source": [
    "mydatabase.collection.getIndexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-combat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-speaking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-casting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-danish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Machine': 332,\n",
    " 'DebugSize': 0,\n",
    " 'DebugRVA': 0,\n",
    " 'MajorImageVersion': 0,\n",
    " 'MajorOSVersion': 5,\n",
    " 'ExportRVA': 0,\n",
    " 'ExportSize': 0,\n",
    " 'IatVRA': 0,\n",
    " 'MajorLinkerVersion': 9,\n",
    " 'MinorLinkerVersion': 0,\n",
    " 'NumberOfSections': 4,\n",
    " 'SizeOfStackReserve': 1048576,\n",
    " 'DllCharacteristics': 32768,\n",
    " 'ResourceSize': 19280,\n",
    " 'BitcoinAddresses': 0}\n",
    "url = \"http://127.0.0.1:8000/predict/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "comparative-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[*] Features extracted successfully.\n",
      "\u001b[0m\n",
      "These are the features ['normalizer3.exe', '46de421fa3f48785fdcf7572d08f61f7', 34404, 28, 66368, 0, 5, 0, 0, 65536, 10, 0, 6, 1048576, 33088, 21492, 0]\n",
      "normalizer3.exe\n"
     ]
    },
    {
     "ename": "DuplicateKeyError",
     "evalue": "E11000 duplicate key error collection: Security.base_tutorial index: __primary_key__ dup key: { id: null }, full error: {'index': 0, 'code': 11000, 'keyPattern': {'id': 1}, 'keyValue': {'id': None}, 'errmsg': 'E11000 duplicate key error collection: Security.base_tutorial index: __primary_key__ dup key: { id: null }'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateKeyError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-abe3503abe9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;34m'date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     }\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"already saved to the database\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_one\u001b[1;34m(self, document, bypass_document_validation, session)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[0mwrite_concern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_concern_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         return InsertOneResult(\n\u001b[1;32m--> 705\u001b[1;33m             self._insert(document,\n\u001b[0m\u001b[0;32m    706\u001b[0m                          \u001b[0mwrite_concern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                          \u001b[0mbypass_doc_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbypass_document_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m_insert\u001b[1;34m(self, docs, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;34m\"\"\"Internal insert helper.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             return self._insert_one(\n\u001b[0m\u001b[0;32m    621\u001b[0m                 \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanipulate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                 bypass_doc_val, session)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m_insert_one\u001b[1;34m(self, doc, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[0m_check_write_command_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m         self.__database.client._retryable_write(\n\u001b[0m\u001b[0;32m    610\u001b[0m             acknowledged, _insert_command, session)\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[1;34m(self, retryable, func, session)\u001b[0m\n\u001b[0;32m   1550\u001b[0m         \u001b[1;34m\"\"\"Internal retryable write helper.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_getlasterror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_retry_with_session\u001b[1;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[0;32m   1436\u001b[0m         retryable = (retryable and self.retry_writes\n\u001b[0;32m   1437\u001b[0m                      and session and not session.in_transaction)\n\u001b[1;32m-> 1438\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_retry_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_retry_internal\u001b[1;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[0;32m   1468\u001b[0m                             \u001b[1;32mraise\u001b[0m \u001b[0mlast_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                         \u001b[0mretryable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1470\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1471\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mServerSelectionTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_retrying\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m_insert_command\u001b[1;34m(session, sock_info, retryable_write)\u001b[0m\n\u001b[0;32m    605\u001b[0m                 retryable_write=retryable_write)\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0m_check_write_command_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         self.__database.client._retryable_write(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\helpers.py\u001b[0m in \u001b[0;36m_check_write_command_response\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[0mwrite_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"writeErrors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0m_raise_last_write_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"writeConcernError\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pymongo\\helpers.py\u001b[0m in \u001b[0;36m_raise_last_write_error\u001b[1;34m(write_errors)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrite_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mDuplicateKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateKeyError\u001b[0m: E11000 duplicate key error collection: Security.base_tutorial index: __primary_key__ dup key: { id: null }, full error: {'index': 0, 'code': 11000, 'keyPattern': {'id': 1}, 'keyValue': {'id': None}, 'errmsg': 'E11000 duplicate key error collection: Security.base_tutorial index: __primary_key__ dup key: { id: null }'}"
     ]
    }
   ],
   "source": [
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "\n",
    "\n",
    "for curFile in os.listdir(\"files\"):\n",
    "    total = []\n",
    "#     ff = curFile\n",
    "    if ff not in filesNames:\n",
    "        total.append(ff)\n",
    "#         extract_features('files/' + total)   \n",
    "    features = extract_features('files/' + ff)     \n",
    "    print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "    print(\"These are the features\", features)\n",
    "    print(features[0])\n",
    "    data2[\"Machine\"].append(features[2])\n",
    "    data2[\"DebugSize\"].append(features[3])\n",
    "    data2[\"DebugRVA\"].append(features[4])\n",
    "    data2[\"MajorImageVersion\"].append(features[5])\n",
    "    data2[\"MajorOSVersion\"].append(features[6])\n",
    "    data2[\"ExportRVA\"].append(features[7])\n",
    "    data2[\"ExportSize\"].append(features[8])\n",
    "    data2[\"IatVRA\"].append(features[9])\n",
    "    data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "    data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "    data2[\"NumberOfSections\"].append(features[12])\n",
    "    data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "    data2[\"DllCharacteristics\"].append(features[14])\n",
    "    data2[\"ResourceSize\"].append(features[15])\n",
    "    data2[\"BitcoinAddresses\"].append(features[16])\n",
    "    url = \"http://127.0.0.1:8000/predict/\"\n",
    "    res = requests.post(url, data2)\n",
    "    res = res.json()\n",
    "    prediction = res['prediction']\n",
    "    prediction[0]\n",
    "#     print(\"This is the prediction for the file\", res.text)\n",
    "    info1 = {\n",
    "    'filename':features[0],\n",
    "    'prediction':prediction[0],\n",
    "    'date':datetime.datetime.utcnow()\n",
    "    }\n",
    "    collection.insert_one(info1)\n",
    "    print(\"already saved to the database\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "endangered-savings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(url, data2)\n",
    "# print(\"This is the prediction for the file\", res.text)\n",
    "res = res.json()\n",
    "prediction = res['prediction']\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "twelve-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = res.json()\n",
    "da['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-christian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-manitoba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "smart-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function get md5 calculates the md5 hash of a given file.\n",
    "def get_md5(file):\n",
    "    \n",
    "    # Note that sometimes you won't be able to fit the whole file in memory.\n",
    "    # In that case, you'll have to read chunks of 4096 bytes\n",
    "    # sequentially and feed them to the Md5 function:\n",
    "    # https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "    \n",
    "    md5 = hashlib.md5()\n",
    "    with open(file, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5.update(chunk)\n",
    "        return md5.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "later-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46de421fa3f48785fdcf7572d08f61f7'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_md5('files/normalizer.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "respected-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interior-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import hashlib\n",
    "import math\n",
    "import array\n",
    "import pefile\n",
    "import yara\n",
    "from termcolor import colored\n",
    "import colorama\n",
    "import pandas as pd\n",
    "\n",
    "# Function get md5 calculates the md5 hash of a given file.\n",
    "def get_md5(file):\n",
    "    \n",
    "    # Note that sometimes you won't be able to fit the whole file in memory.\n",
    "    # In that case, you'll have to read chunks of 4096 bytes\n",
    "    # sequentially and feed them to the Md5 function:\n",
    "    # https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "    \n",
    "    md5 = hashlib.md5()\n",
    "    with open(file, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5.update(chunk)\n",
    "        return md5.hexdigest()\n",
    "\n",
    "# Function compile bitcoin compiles the yara rule for detecting\n",
    "# bitcoin addresses within ransomware files. The rule is then\n",
    "# saved in a directory to later be used.\n",
    "def compile_bitcoin():\n",
    "    if not os.path.isdir(\"rules_compiled/Bitcoin\"):\n",
    "        os.makedirs(\"rules_compiled/Bitcoin\")\n",
    "        print(\"success\")\n",
    "\n",
    "    for n in os.listdir(\"rules/Bitcoin\"):\n",
    "        rule = yara.compile(\"rules/Bitcoin/\" + n)\n",
    "        rule.save(\"rules_compiled/Bitcoin/\" + n)\n",
    "\n",
    "# Function check bitcoin loads the bitcoin yara rule\n",
    "# and checks a file for any signs of bitcoin addresses.\n",
    "# If a bitcoin address is found a binary 1 is returned.\n",
    "def check_bitcoin(filepath):\n",
    "    for n in os.listdir(\"rules/Bitcoin\"):\n",
    "        rule = yara.load(\"rules_compiled/Bitcoin/\" + n)\n",
    "        m = rule.match(filepath)\n",
    "        if m:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Function extract features extracts all features from the input file.\n",
    "# Features are stored in a list and then returned to later be written to\n",
    "# a csv file. \n",
    "def extract_features(file):\n",
    "    # Creates an empty list for which features can later be appended into.\n",
    "    features = []\n",
    "\n",
    "    # Name of file\n",
    "    features.append(os.path.basename(file))\n",
    "\n",
    "    # MD5 hash\n",
    "    features.append(get_md5(file))\n",
    "\n",
    "    # Assigns pe to the input file. fast_load loads all directory information.\n",
    "    pe = pefile.PE(file, fast_load=True)\n",
    "\n",
    "    # CPU that the file is intended for.\n",
    "    features.append(pe.FILE_HEADER.Machine)\n",
    "\n",
    "    # DebugSize is the size of the debug directory table. Clean files typically have a debug directory\n",
    "    # and thus, will have a non-zero values.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].Size)\n",
    "\n",
    "    # DebugRVA\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].VirtualAddress)\n",
    "\n",
    "    # MajorImageVersion is the version of the file. This is user defined and for clean programs is often\n",
    "    # populated. Malware often has a value of 0 for this.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorImageVersion)\n",
    "\n",
    "    # MajorOSVersion is the major operating system required to run exe.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)\n",
    "\n",
    "    # ExportRVA.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].VirtualAddress)\n",
    "\n",
    "    # ExportSize is the size of the export table. Usually non-zero for clean files.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].Size)\n",
    "\n",
    "    # IatRVA is the relative virtual address of import address table. Most clean files have 4096 for this\n",
    "    # where as malware often has 0 or a very large number.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[12].VirtualAddress)\n",
    "\n",
    "    # Version of linker that produced file.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)\n",
    "    features.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)\n",
    "\n",
    "    # NumberOfSections is the number of sections in file.\n",
    "    features.append(pe.FILE_HEADER.NumberOfSections)\n",
    "\n",
    "    # SizeOfStackReserve denotes the amount of virtual memory to reserve for the initial thread's stack.\n",
    "    features.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)\n",
    "\n",
    "    # DllCharacteristics is a set of flags indicating under which circumstances a DLL's initialization\n",
    "    # function will be called.\n",
    "    features.append(pe.OPTIONAL_HEADER.DllCharacteristics)\n",
    "\n",
    "    # MinResourcesSize is the size of resources section of PE header. Malware sometimes has 0 resources.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[2].Size)\n",
    "\n",
    "    # Calls the bitcoin_check function to check if the file contains a bitcoin address.\n",
    "    bitcoin_check = check_bitcoin(file)\n",
    "    features.append(bitcoin_check)\n",
    "\n",
    "    # Returns the feature list.\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "rough-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizer.exe',\n",
       " '46de421fa3f48785fdcf7572d08f61f7',\n",
       " 34404,\n",
       " 28,\n",
       " 66368,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 65536,\n",
       " 10,\n",
       " 0,\n",
       " 6,\n",
       " 1048576,\n",
       " 33088,\n",
       " 21492,\n",
       " 0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_features(r'C:\\Users\\Mustapha\\Desktop\\New_folder_(2)\\Django_project\\security\\MLRD-Machine-Learning-Ransomware-Detection\\benign\\normalizer.exe')    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "black-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dict[\"Name\"].append(df[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "confused-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_string = json.dumps(df)\n",
    "# print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "sensitive-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Extracting features from  normalizer.exe\n",
      "34404\n",
      "[*] Features extracted successfully.\n",
      "\n",
      "This is the prediction for the file {\"prediction\":[0]}\n",
      "normalizer.exe\n",
      "\n",
      "[+] Extracting features from  test.txt\n",
      "[-] Error: Unable to extract features.\n",
      "\n",
      "test.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "for f in os.listdir('benign/'):\n",
    "    print(\"\\n[+] Extracting features from \", f)\n",
    "    try:\n",
    "        features = extract_features(os.path.join('benign/', f))\n",
    "        print(features[2])\n",
    "#             features.append(1)\n",
    "#             feature_file.write(csv_delimeter.join(map(lambda x: str(x), features)) + \"\\n\")\n",
    "        print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "        data2[\"Machine\"].append(features[2])\n",
    "        data2[\"DebugSize\"].append(features[3])\n",
    "        data2[\"DebugRVA\"].append(features[4])\n",
    "        data2[\"MajorImageVersion\"].append(features[5])\n",
    "        data2[\"MajorOSVersion\"].append(features[6])\n",
    "        data2[\"ExportRVA\"].append(features[7])\n",
    "        data2[\"ExportSize\"].append(features[8])\n",
    "        data2[\"IatVRA\"].append(features[9])\n",
    "        data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "        data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "        data2[\"NumberOfSections\"].append(features[12])\n",
    "        data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "        data2[\"DllCharacteristics\"].append(features[14])\n",
    "        data2[\"ResourceSize\"].append(features[15])\n",
    "        data2[\"BitcoinAddresses\"].append(features[16])\n",
    "        res = requests.post(url, data)\n",
    "        print(\"This is the prediction for the file\", res.text)\n",
    "    except:\n",
    "        print(colored(\"[-] Error: Unable to extract features.\\n\", 'red'))\n",
    "\n",
    "    feature_file.close()\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-philip",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-bryan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "architectural-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "european-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"Machine\"].append(df[2])\n",
    "data2[\"DebugSize\"].append(df[3])\n",
    "data2[\"DebugRVA\"].append(df[4])\n",
    "data2[\"MajorImageVersion\"].append(df[5])\n",
    "data2[\"MajorOSVersion\"].append(df[6])\n",
    "data2[\"ExportRVA\"].append(df[7])\n",
    "data2[\"ExportSize\"].append(df[8])\n",
    "data2[\"IatVRA\"].append(df[9])\n",
    "data2[\"MajorLinkerVersion\"].append(df[10])\n",
    "data2[\"MinorLinkerVersion\"].append(df[11])\n",
    "data2[\"NumberOfSections\"].append(df[12])\n",
    "data2[\"SizeOfStackReserve\"].append(df[13])\n",
    "data2[\"DllCharacteristics\"].append(df[14])\n",
    "data2[\"ResourceSize\"].append(df[15])\n",
    "data2[\"BitcoinAddresses\"].append(df[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "generic-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "opposed-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine': [34404],\n",
       " 'DebugSize': [28],\n",
       " 'DebugRVA': [66368],\n",
       " 'MajorImageVersion': [0],\n",
       " 'MajorOSVersion': [5],\n",
       " 'ExportRVA': [0],\n",
       " 'ExportSize': [0],\n",
       " 'IatVRA': [65536],\n",
       " 'MajorLinkerVersion': [10],\n",
       " 'MinorLinkerVersion': [0],\n",
       " 'NumberOfSections': [6],\n",
       " 'SizeOfStackReserve': [1048576],\n",
       " 'DllCharacteristics': [33088],\n",
       " 'ResourceSize': [21492],\n",
       " 'BitcoinAddresses': [0]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "august-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "lucky-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/predict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "rental-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(url, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "known-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\":[0]}'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-division",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-border",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-athens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-edition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-maine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-hundred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "administrative-stability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46de421fa3f48785fdcf7572d08f61f7'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "synthetic-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34404"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "wrapped-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "comic-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_string[\"normalizer.exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-posting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "computational-characteristic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine': 332,\n",
       " 'DebugSize': 0,\n",
       " 'DebugRVA': 0,\n",
       " 'MajorImageVersion': 0,\n",
       " 'MajorOSVersion': 5,\n",
       " 'ExportRVA': 0,\n",
       " 'ExportSize': 0,\n",
       " 'IatVRA': 0,\n",
       " 'MajorLinkerVersion': 9,\n",
       " 'MinorLinkerVersion': 0,\n",
       " 'NumberOfSections': 4,\n",
       " 'SizeOfStackReserve': 1048576,\n",
       " 'DllCharacteristics': 32768,\n",
       " 'ResourceSize': 19280,\n",
       " 'BitcoinAddresses': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "widespread-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "institutional-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"normalizer.exe\", \"46de421fa3f48785fdcf7572d08f61f7\", 34404, 28, 66368, 0, 5, 0, 0, 65536, 10, 0, 6, 1048576, 33088, 21492, 0]\n"
     ]
    }
   ],
   "source": [
    "json_string = json.dumps(data)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loaded-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/predict/'\n",
    "data =  {\n",
    "   \"Machine\" : 332,\n",
    "    \"DebugSize\" : 0,\n",
    "    \"DebugRVA\" :  0,\n",
    "    \"MajorImageVersion\" : 0,\n",
    "    \"MajorOSVersion\" : 5,\n",
    "    \"ExportRVA\" : 0,\n",
    "    \"ExportSize\": 0,\n",
    "    \"IatVRA\" : 0,\n",
    "    \"MajorLinkerVersion\" : 9,\n",
    "    \"MinorLinkerVersion\" : 0,\n",
    "    \"NumberOfSections\" : 4,\n",
    "    \"SizeOfStackReserve\" : 1048576,\n",
    "    \"DllCharacteristics\" :  32768,\n",
    "    \"ResourceSize\" : 19280,\n",
    "    \"BitcoinAddresses\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-upper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-brooks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "unavailable-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Extracting features from  normalizer.exe\n",
      "[*] Features extracted successfully.\n",
      "\n",
      "\n",
      "[+] Extracting features from  test.txt\n",
      "[-] Error: Unable to extract features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    output_file = \"data4_benign.csv\"\n",
    "    csv_delimeter = ','\n",
    "    csv_columns = [\n",
    "        \"FileName\",\n",
    "        \"md5Hash\",\n",
    "        \"Machine\",\n",
    "        \"DebugSize\",\n",
    "        \"DebugRVA\",\n",
    "        \"MajorImageVersion\",\n",
    "        \"MajorOSVersion\",\n",
    "        \"ExportRVA\",\n",
    "        \"ExportSize\",\n",
    "        \"IatVRA\",\n",
    "        \"MajorLinkerVersion\",\n",
    "        \"MinorLinkerVersion\",\n",
    "        \"NumberOfSections\",\n",
    "        \"SizeOfStackReserve\",\n",
    "        \"DllCharacteristics\",\n",
    "        \"ResourceSize\",\n",
    "        \"BitcoinAddresses\",\n",
    "        \"Benign\",\n",
    "    ]\n",
    "\n",
    "    # Compiles the yara rule for bitcoin address detection.\n",
    "    compile_bitcoin()\n",
    "\n",
    "    # Opens file so features can be written too.\n",
    "    feature_file = open(output_file, 'a')\n",
    "    \n",
    "    # Writes column headers to feature file.\n",
    "    if not csv_columns:\n",
    "        feature_file.write(csv_delimeter.join(csv_columns) + \"\\n\")\n",
    "    else:\n",
    "#         csv_columns\n",
    "#         continue\n",
    "        pass\n",
    "    colorama.init()\n",
    "    # Extracts features from benign files and writes to CSV.\n",
    "    for f in os.listdir('benign/'):\n",
    "        print(\"\\n[+] Extracting features from \", f)\n",
    "        try:\n",
    "            features = extract_features(os.path.join('benign/', f))\n",
    "            features.append(1)\n",
    "            feature_file.write(csv_delimeter.join(map(lambda x: str(x), features)) + \"\\n\")\n",
    "            print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "        except:\n",
    "            print(colored(\"[-] Error: Unable to extract features.\\n\", 'red'))\n",
    "\n",
    "    feature_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "precious-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-release",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-association",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
