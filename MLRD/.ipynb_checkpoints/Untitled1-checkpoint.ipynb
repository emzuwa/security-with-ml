{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elegant-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loose-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the files names at the folder\n",
    "def nameOfFiles():\n",
    "    filesNames = [f for f in listdir(\"files\") if isfile(join(\"files\", f))]\n",
    "    return(filesNames)\n",
    "nameOfFiles()\n",
    "\n",
    "#calculate the digest of each file and append to a final file\n",
    "#that will later save to a txt\n",
    "def main():\n",
    "    filesHash = ''\n",
    "    sha512 = hashlib.sha512()\n",
    "    for i in filesNames:\n",
    "        with open(\"files/\"+ i, \"rb\") as f:\n",
    "            while True:\n",
    "                data = f.read()\n",
    "                if not data:\n",
    "                    break\n",
    "                sha512.update(data)\n",
    "                filesHash+=(sha512.hexdigest())\n",
    "    return(filesHash)\n",
    "\n",
    "def createControlFile():\n",
    "    with open('fileControlData.txt','w',encoding = 'utf-8') as f:\n",
    "        for i in fileControl: f.write(i)\n",
    "    print(\"File generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "appropriate-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file was added, do you wanna to recreate the control File?(y/n)y\n",
      "File generated!\n",
      "7666\n",
      "['normalizer.exe'] 23456\n"
     ]
    }
   ],
   "source": [
    "filesNames = nameOfFiles()\n",
    "fileControl = main()\n",
    "\n",
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "# while True:\n",
    "if os.path.exists(\"fileControlData.txt\") is True:\n",
    "    with open('fileControlData.txt','r',encoding = 'utf-8') as file:\n",
    "        file = file.read()\n",
    "        if file == fileControl:\n",
    "            print(\"The files are intact!\")\n",
    "        else:\n",
    "            if len(fileControl)> len(file):\n",
    "                answer = input(\"A file was added, do you wanna to recreate the control File?(y/n)\").lower()\n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "                print(os.listdir(\"files\"), \"23456\")\n",
    "                for curFile in os.listdir(\"files\"):\n",
    "                    ff = curFile\n",
    "    #                     break\n",
    "                    print(filesNames)\n",
    "                    if ff not in filesNames:  \n",
    "                        features = extract_features('files/' + ff) \n",
    "                        data2 =  {\n",
    "                                   \"Machine\" : [],\n",
    "                                    \"DebugSize\" :[],\n",
    "                                    \"DebugRVA\" :  [],\n",
    "                                    \"MajorImageVersion\" : [],\n",
    "                                    \"MajorOSVersion\" : [],\n",
    "                                    \"ExportRVA\" : [],\n",
    "                                    \"ExportSize\": [],\n",
    "                                    \"IatVRA\" : [],\n",
    "                                    \"MajorLinkerVersion\" : [],\n",
    "                                    \"MinorLinkerVersion\" : [],\n",
    "                                    \"NumberOfSections\" : [],\n",
    "                                    \"SizeOfStackReserve\" : [],\n",
    "                                    \"DllCharacteristics\" :  [],\n",
    "                                    \"ResourceSize\" : [],\n",
    "                                    \"BitcoinAddresses\" : []\n",
    "                                }\n",
    "                        print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "                        data2[\"Machine\"].append(features[2])\n",
    "                        data2[\"DebugSize\"].append(features[3])\n",
    "                        data2[\"DebugRVA\"].append(features[4])\n",
    "                        data2[\"MajorImageVersion\"].append(features[5])\n",
    "                        data2[\"MajorOSVersion\"].append(features[6])\n",
    "                        data2[\"ExportRVA\"].append(features[7])\n",
    "                        data2[\"ExportSize\"].append(features[8])\n",
    "                        data2[\"IatVRA\"].append(features[9])\n",
    "                        data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "                        data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "                        data2[\"NumberOfSections\"].append(features[12])\n",
    "                        data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "                        data2[\"DllCharacteristics\"].append(features[14])\n",
    "                        data2[\"ResourceSize\"].append(features[15])\n",
    "                        data2[\"BitcoinAddresses\"].append(features[16])\n",
    "                        url = \"http://127.0.0.1:8000/predict/\"\n",
    "                        res = requests.post(url, data2)\n",
    "                        print(\"This is the prediction for the file\", res.text)\n",
    "            elif len(fileControl)< len(file): \n",
    "                answer = input(\"A file was removed, do you wanna to recreate the control File?(y/n)\").lower()\n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "            else:\n",
    "                answer = input(\"The files have been changed, do you wanna to recreate the control File?(y/n)\").lower()            \n",
    "                if answer == \"y\":\n",
    "                    createControlFile()\n",
    "else:\n",
    "    createControlFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-renaissance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-corpus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "entire-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizer.exe']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "scientific-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Machine': 332,\n",
    " 'DebugSize': 0,\n",
    " 'DebugRVA': 0,\n",
    " 'MajorImageVersion': 0,\n",
    " 'MajorOSVersion': 5,\n",
    " 'ExportRVA': 0,\n",
    " 'ExportSize': 0,\n",
    " 'IatVRA': 0,\n",
    " 'MajorLinkerVersion': 9,\n",
    " 'MinorLinkerVersion': 0,\n",
    " 'NumberOfSections': 4,\n",
    " 'SizeOfStackReserve': 1048576,\n",
    " 'DllCharacteristics': 32768,\n",
    " 'ResourceSize': 19280,\n",
    " 'BitcoinAddresses': 0}\n",
    "url = \"http://127.0.0.1:8000/predict/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "comparative-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[*] Features extracted successfully.\n",
      "\u001b[0m\n",
      "This is the prediction for the file {\"prediction\":[1]}\n"
     ]
    }
   ],
   "source": [
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "\n",
    "\n",
    "for curFile in os.listdir(\"files\"):\n",
    "    total = []\n",
    "#     ff = curFile\n",
    "    if ff not in filesNames:\n",
    "        total.append(ff)\n",
    "#         extract_features('files/' + total)   \n",
    "    features = extract_features('files/' + ff)     \n",
    "    print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "    data2[\"Machine\"].append(features[2])\n",
    "    data2[\"DebugSize\"].append(features[3])\n",
    "    data2[\"DebugRVA\"].append(features[4])\n",
    "    data2[\"MajorImageVersion\"].append(features[5])\n",
    "    data2[\"MajorOSVersion\"].append(features[6])\n",
    "    data2[\"ExportRVA\"].append(features[7])\n",
    "    data2[\"ExportSize\"].append(features[8])\n",
    "    data2[\"IatVRA\"].append(features[9])\n",
    "    data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "    data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "    data2[\"NumberOfSections\"].append(features[12])\n",
    "    data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "    data2[\"DllCharacteristics\"].append(features[14])\n",
    "    data2[\"ResourceSize\"].append(features[15])\n",
    "    data2[\"BitcoinAddresses\"].append(features[16])\n",
    "    url = \"http://127.0.0.1:8000/predict/\"\n",
    "    res = requests.post(url, data2)\n",
    "    print(\"This is the prediction for the file\", res.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "smart-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function get md5 calculates the md5 hash of a given file.\n",
    "def get_md5(file):\n",
    "    \n",
    "    # Note that sometimes you won't be able to fit the whole file in memory.\n",
    "    # In that case, you'll have to read chunks of 4096 bytes\n",
    "    # sequentially and feed them to the Md5 function:\n",
    "    # https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "    \n",
    "    md5 = hashlib.md5()\n",
    "    with open(file, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5.update(chunk)\n",
    "        return md5.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "later-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46de421fa3f48785fdcf7572d08f61f7'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_md5('files/normalizer.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "respected-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interior-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import hashlib\n",
    "import math\n",
    "import array\n",
    "import pefile\n",
    "import yara\n",
    "from termcolor import colored\n",
    "import colorama\n",
    "import pandas as pd\n",
    "\n",
    "# Function get md5 calculates the md5 hash of a given file.\n",
    "def get_md5(file):\n",
    "    \n",
    "    # Note that sometimes you won't be able to fit the whole file in memory.\n",
    "    # In that case, you'll have to read chunks of 4096 bytes\n",
    "    # sequentially and feed them to the Md5 function:\n",
    "    # https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "    \n",
    "    md5 = hashlib.md5()\n",
    "    with open(file, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            md5.update(chunk)\n",
    "        return md5.hexdigest()\n",
    "\n",
    "# Function compile bitcoin compiles the yara rule for detecting\n",
    "# bitcoin addresses within ransomware files. The rule is then\n",
    "# saved in a directory to later be used.\n",
    "def compile_bitcoin():\n",
    "    if not os.path.isdir(\"rules_compiled/Bitcoin\"):\n",
    "        os.makedirs(\"rules_compiled/Bitcoin\")\n",
    "        print(\"success\")\n",
    "\n",
    "    for n in os.listdir(\"rules/Bitcoin\"):\n",
    "        rule = yara.compile(\"rules/Bitcoin/\" + n)\n",
    "        rule.save(\"rules_compiled/Bitcoin/\" + n)\n",
    "\n",
    "# Function check bitcoin loads the bitcoin yara rule\n",
    "# and checks a file for any signs of bitcoin addresses.\n",
    "# If a bitcoin address is found a binary 1 is returned.\n",
    "def check_bitcoin(filepath):\n",
    "    for n in os.listdir(\"rules/Bitcoin\"):\n",
    "        rule = yara.load(\"rules_compiled/Bitcoin/\" + n)\n",
    "        m = rule.match(filepath)\n",
    "        if m:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Function extract features extracts all features from the input file.\n",
    "# Features are stored in a list and then returned to later be written to\n",
    "# a csv file. \n",
    "def extract_features(file):\n",
    "    # Creates an empty list for which features can later be appended into.\n",
    "    features = []\n",
    "\n",
    "    # Name of file\n",
    "    features.append(os.path.basename(file))\n",
    "\n",
    "    # MD5 hash\n",
    "    features.append(get_md5(file))\n",
    "\n",
    "    # Assigns pe to the input file. fast_load loads all directory information.\n",
    "    pe = pefile.PE(file, fast_load=True)\n",
    "\n",
    "    # CPU that the file is intended for.\n",
    "    features.append(pe.FILE_HEADER.Machine)\n",
    "\n",
    "    # DebugSize is the size of the debug directory table. Clean files typically have a debug directory\n",
    "    # and thus, will have a non-zero values.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].Size)\n",
    "\n",
    "    # DebugRVA\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].VirtualAddress)\n",
    "\n",
    "    # MajorImageVersion is the version of the file. This is user defined and for clean programs is often\n",
    "    # populated. Malware often has a value of 0 for this.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorImageVersion)\n",
    "\n",
    "    # MajorOSVersion is the major operating system required to run exe.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)\n",
    "\n",
    "    # ExportRVA.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].VirtualAddress)\n",
    "\n",
    "    # ExportSize is the size of the export table. Usually non-zero for clean files.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].Size)\n",
    "\n",
    "    # IatRVA is the relative virtual address of import address table. Most clean files have 4096 for this\n",
    "    # where as malware often has 0 or a very large number.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[12].VirtualAddress)\n",
    "\n",
    "    # Version of linker that produced file.\n",
    "    features.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)\n",
    "    features.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)\n",
    "\n",
    "    # NumberOfSections is the number of sections in file.\n",
    "    features.append(pe.FILE_HEADER.NumberOfSections)\n",
    "\n",
    "    # SizeOfStackReserve denotes the amount of virtual memory to reserve for the initial thread's stack.\n",
    "    features.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)\n",
    "\n",
    "    # DllCharacteristics is a set of flags indicating under which circumstances a DLL's initialization\n",
    "    # function will be called.\n",
    "    features.append(pe.OPTIONAL_HEADER.DllCharacteristics)\n",
    "\n",
    "    # MinResourcesSize is the size of resources section of PE header. Malware sometimes has 0 resources.\n",
    "    features.append(pe.OPTIONAL_HEADER.DATA_DIRECTORY[2].Size)\n",
    "\n",
    "    # Calls the bitcoin_check function to check if the file contains a bitcoin address.\n",
    "    bitcoin_check = check_bitcoin(file)\n",
    "    features.append(bitcoin_check)\n",
    "\n",
    "    # Returns the feature list.\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "rough-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizer.exe',\n",
       " '46de421fa3f48785fdcf7572d08f61f7',\n",
       " 34404,\n",
       " 28,\n",
       " 66368,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 65536,\n",
       " 10,\n",
       " 0,\n",
       " 6,\n",
       " 1048576,\n",
       " 33088,\n",
       " 21492,\n",
       " 0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_features(r'C:\\Users\\Mustapha\\Desktop\\New_folder_(2)\\Django_project\\security\\MLRD-Machine-Learning-Ransomware-Detection\\benign\\normalizer.exe')    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "black-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dict[\"Name\"].append(df[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "confused-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_string = json.dumps(df)\n",
    "# print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "sensitive-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Extracting features from  normalizer.exe\n",
      "34404\n",
      "[*] Features extracted successfully.\n",
      "\n",
      "This is the prediction for the file {\"prediction\":[0]}\n",
      "normalizer.exe\n",
      "\n",
      "[+] Extracting features from  test.txt\n",
      "[-] Error: Unable to extract features.\n",
      "\n",
      "test.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}\n",
    "for f in os.listdir('benign/'):\n",
    "    print(\"\\n[+] Extracting features from \", f)\n",
    "    try:\n",
    "        features = extract_features(os.path.join('benign/', f))\n",
    "        print(features[2])\n",
    "#             features.append(1)\n",
    "#             feature_file.write(csv_delimeter.join(map(lambda x: str(x), features)) + \"\\n\")\n",
    "        print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "        data2[\"Machine\"].append(features[2])\n",
    "        data2[\"DebugSize\"].append(features[3])\n",
    "        data2[\"DebugRVA\"].append(features[4])\n",
    "        data2[\"MajorImageVersion\"].append(features[5])\n",
    "        data2[\"MajorOSVersion\"].append(features[6])\n",
    "        data2[\"ExportRVA\"].append(features[7])\n",
    "        data2[\"ExportSize\"].append(features[8])\n",
    "        data2[\"IatVRA\"].append(features[9])\n",
    "        data2[\"MajorLinkerVersion\"].append(features[10])\n",
    "        data2[\"MinorLinkerVersion\"].append(features[11])\n",
    "        data2[\"NumberOfSections\"].append(features[12])\n",
    "        data2[\"SizeOfStackReserve\"].append(features[13])\n",
    "        data2[\"DllCharacteristics\"].append(features[14])\n",
    "        data2[\"ResourceSize\"].append(features[15])\n",
    "        data2[\"BitcoinAddresses\"].append(features[16])\n",
    "        res = requests.post(url, data)\n",
    "        print(\"This is the prediction for the file\", res.text)\n",
    "    except:\n",
    "        print(colored(\"[-] Error: Unable to extract features.\\n\", 'red'))\n",
    "\n",
    "    feature_file.close()\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-philip",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-bryan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "architectural-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 =  {\n",
    "   \"Machine\" : [],\n",
    "    \"DebugSize\" :[],\n",
    "    \"DebugRVA\" :  [],\n",
    "    \"MajorImageVersion\" : [],\n",
    "    \"MajorOSVersion\" : [],\n",
    "    \"ExportRVA\" : [],\n",
    "    \"ExportSize\": [],\n",
    "    \"IatVRA\" : [],\n",
    "    \"MajorLinkerVersion\" : [],\n",
    "    \"MinorLinkerVersion\" : [],\n",
    "    \"NumberOfSections\" : [],\n",
    "    \"SizeOfStackReserve\" : [],\n",
    "    \"DllCharacteristics\" :  [],\n",
    "    \"ResourceSize\" : [],\n",
    "    \"BitcoinAddresses\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "european-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"Machine\"].append(df[2])\n",
    "data2[\"DebugSize\"].append(df[3])\n",
    "data2[\"DebugRVA\"].append(df[4])\n",
    "data2[\"MajorImageVersion\"].append(df[5])\n",
    "data2[\"MajorOSVersion\"].append(df[6])\n",
    "data2[\"ExportRVA\"].append(df[7])\n",
    "data2[\"ExportSize\"].append(df[8])\n",
    "data2[\"IatVRA\"].append(df[9])\n",
    "data2[\"MajorLinkerVersion\"].append(df[10])\n",
    "data2[\"MinorLinkerVersion\"].append(df[11])\n",
    "data2[\"NumberOfSections\"].append(df[12])\n",
    "data2[\"SizeOfStackReserve\"].append(df[13])\n",
    "data2[\"DllCharacteristics\"].append(df[14])\n",
    "data2[\"ResourceSize\"].append(df[15])\n",
    "data2[\"BitcoinAddresses\"].append(df[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "generic-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "opposed-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine': [34404],\n",
       " 'DebugSize': [28],\n",
       " 'DebugRVA': [66368],\n",
       " 'MajorImageVersion': [0],\n",
       " 'MajorOSVersion': [5],\n",
       " 'ExportRVA': [0],\n",
       " 'ExportSize': [0],\n",
       " 'IatVRA': [65536],\n",
       " 'MajorLinkerVersion': [10],\n",
       " 'MinorLinkerVersion': [0],\n",
       " 'NumberOfSections': [6],\n",
       " 'SizeOfStackReserve': [1048576],\n",
       " 'DllCharacteristics': [33088],\n",
       " 'ResourceSize': [21492],\n",
       " 'BitcoinAddresses': [0]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "august-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "lucky-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/predict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "rental-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(url, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "known-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\":[0]}'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-division",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-border",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-athens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-edition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-maine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-hundred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "administrative-stability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46de421fa3f48785fdcf7572d08f61f7'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "synthetic-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34404"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "wrapped-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "comic-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_string[\"normalizer.exe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "stainless-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': [28], 'Address': [], 'Age': []}\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"Name\":[],\"Address\":[],\"Age\":[]};\n",
    "\n",
    "my_dict[\"Name\"].append(df[3])\n",
    "# my_dict[\"Address\"].append(\"Mumbai\")\n",
    "# my_dict[\"Age\"].append(30)\t\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "computational-characteristic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine': 332,\n",
       " 'DebugSize': 0,\n",
       " 'DebugRVA': 0,\n",
       " 'MajorImageVersion': 0,\n",
       " 'MajorOSVersion': 5,\n",
       " 'ExportRVA': 0,\n",
       " 'ExportSize': 0,\n",
       " 'IatVRA': 0,\n",
       " 'MajorLinkerVersion': 9,\n",
       " 'MinorLinkerVersion': 0,\n",
       " 'NumberOfSections': 4,\n",
       " 'SizeOfStackReserve': 1048576,\n",
       " 'DllCharacteristics': 32768,\n",
       " 'ResourceSize': 19280,\n",
       " 'BitcoinAddresses': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "widespread-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "institutional-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"normalizer.exe\", \"46de421fa3f48785fdcf7572d08f61f7\", 34404, 28, 66368, 0, 5, 0, 0, 65536, 10, 0, 6, 1048576, 33088, 21492, 0]\n"
     ]
    }
   ],
   "source": [
    "json_string = json.dumps(data)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loaded-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/predict/'\n",
    "data =  {\n",
    "   \"Machine\" : 332,\n",
    "    \"DebugSize\" : 0,\n",
    "    \"DebugRVA\" :  0,\n",
    "    \"MajorImageVersion\" : 0,\n",
    "    \"MajorOSVersion\" : 5,\n",
    "    \"ExportRVA\" : 0,\n",
    "    \"ExportSize\": 0,\n",
    "    \"IatVRA\" : 0,\n",
    "    \"MajorLinkerVersion\" : 9,\n",
    "    \"MinorLinkerVersion\" : 0,\n",
    "    \"NumberOfSections\" : 4,\n",
    "    \"SizeOfStackReserve\" : 1048576,\n",
    "    \"DllCharacteristics\" :  32768,\n",
    "    \"ResourceSize\" : 19280,\n",
    "    \"BitcoinAddresses\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-upper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-brooks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "unavailable-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Extracting features from  normalizer.exe\n",
      "[*] Features extracted successfully.\n",
      "\n",
      "\n",
      "[+] Extracting features from  test.txt\n",
      "[-] Error: Unable to extract features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    output_file = \"data4_benign.csv\"\n",
    "    csv_delimeter = ','\n",
    "    csv_columns = [\n",
    "        \"FileName\",\n",
    "        \"md5Hash\",\n",
    "        \"Machine\",\n",
    "        \"DebugSize\",\n",
    "        \"DebugRVA\",\n",
    "        \"MajorImageVersion\",\n",
    "        \"MajorOSVersion\",\n",
    "        \"ExportRVA\",\n",
    "        \"ExportSize\",\n",
    "        \"IatVRA\",\n",
    "        \"MajorLinkerVersion\",\n",
    "        \"MinorLinkerVersion\",\n",
    "        \"NumberOfSections\",\n",
    "        \"SizeOfStackReserve\",\n",
    "        \"DllCharacteristics\",\n",
    "        \"ResourceSize\",\n",
    "        \"BitcoinAddresses\",\n",
    "        \"Benign\",\n",
    "    ]\n",
    "\n",
    "    # Compiles the yara rule for bitcoin address detection.\n",
    "    compile_bitcoin()\n",
    "\n",
    "    # Opens file so features can be written too.\n",
    "    feature_file = open(output_file, 'a')\n",
    "    \n",
    "    # Writes column headers to feature file.\n",
    "    if not csv_columns:\n",
    "        feature_file.write(csv_delimeter.join(csv_columns) + \"\\n\")\n",
    "    else:\n",
    "#         csv_columns\n",
    "#         continue\n",
    "        pass\n",
    "    colorama.init()\n",
    "    # Extracts features from benign files and writes to CSV.\n",
    "    for f in os.listdir('benign/'):\n",
    "        print(\"\\n[+] Extracting features from \", f)\n",
    "        try:\n",
    "            features = extract_features(os.path.join('benign/', f))\n",
    "            features.append(1)\n",
    "            feature_file.write(csv_delimeter.join(map(lambda x: str(x), features)) + \"\\n\")\n",
    "            print(colored(\"[*] Features extracted successfully.\\n\", 'green'))\n",
    "        except:\n",
    "            print(colored(\"[-] Error: Unable to extract features.\\n\", 'red'))\n",
    "\n",
    "    feature_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "precious-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-release",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-association",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
